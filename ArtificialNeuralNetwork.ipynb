{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('clean_steam_data.csv')\n",
    "# print(data.shape)\n",
    "# data = data[data['Reviews'] > 0]\n",
    "# print(data.shape)\n",
    "data.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# columns = data.columns\n",
    "# data = pd.DataFrame( scaler.fit_transform(data), columns=columns)\n",
    "\n",
    "\n",
    "\n",
    "train, test = train_test_split(data, train_size=0.75,test_size= 0.25,random_state=123 )\n",
    "\n",
    "y_train = train['Reviews'].copy()\n",
    "y_test  = test['Reviews'].copy()\n",
    "\n",
    "train.drop([\"Reviews\"], axis=1, inplace=True) #,'Day_sin', 'Day_cos', 'Month_sin', 'Month_cos'\n",
    "test.drop( [\"Reviews\"], axis=1, inplace=True) #,'Day_sin', 'Day_cos', 'Month_sin', 'Month_cos'\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# train = scaler.fit_transform(train)\n",
    "x_train  = train.copy()\n",
    "x_test   = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6474.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2236.479302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3817.687066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>347.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>781.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2227.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34054.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Reviews\n",
       "count   6474.000000\n",
       "mean    2236.479302\n",
       "std     3817.687066\n",
       "min       22.000000\n",
       "25%      347.000000\n",
       "50%      781.000000\n",
       "75%     2227.500000\n",
       "max    34054.000000"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# ytrain = np.array(y_train)\n",
    "# ytrain = ytrain.reshape(-1, 1)\n",
    "# ytrain = scaler.fit_transform(y_train)\n",
    "ytrain = pd.DataFrame(y_train)\n",
    "ytrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tf.keras.Input(shape=(91,))\n",
    "# x = tf.keras.layers.Dense(128, activation='relu')(inputs)\n",
    "# x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "# outputs = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "# model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "# optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=optimizer,\n",
    "#     loss='mse'\n",
    "# )\n",
    "\n",
    "\n",
    "# batch_size = 64\n",
    "# epochs = 18\n",
    "\n",
    "# history = model.fit(\n",
    "#     x_train,\n",
    "#     y_train,\n",
    "#     validation_split=0.2,\n",
    "#     batch_size=batch_size,\n",
    "#     epochs=epochs,\n",
    "#     verbose=0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEarlyStopping(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs['val_loss'] < 80:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 1s 7ms/step - loss: 6045099.5000 - val_loss: 691296.6875\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1511962.1250 - val_loss: 52609.9141\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 757321.3750 - val_loss: 21188.0039\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 604378.9375 - val_loss: 160710.3281\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 467321.7812 - val_loss: 20080.8457\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 319290.6250 - val_loss: 22361.1465\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 333905.6250 - val_loss: 292678.3125\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 316109.0312 - val_loss: 62546.2734\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 218300.7031 - val_loss: 785319.6875\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 199678.1562 - val_loss: 5201.6763\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 114882.9141 - val_loss: 39514.6094\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 114648.1562 - val_loss: 3510.7158\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 116405.5938 - val_loss: 522500.1875\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 98930.4844 - val_loss: 9203.5850\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 45252.8711 - val_loss: 1656.4850\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 77423.3125 - val_loss: 1175.9489\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 44027.8438 - val_loss: 1065.6511\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 26802.5703 - val_loss: 9190.0391\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 29593.5312 - val_loss: 364.9490\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 16941.2070 - val_loss: 6323.4136\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 11207.5508 - val_loss: 347.3777\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5837.3584 - val_loss: 18819.9961\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2935.0117 - val_loss: 151.3056\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 727.8201 - val_loss: 113.1076\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 55.8006 - val_loss: 97.9771\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 53.4075 - val_loss: 101.3510\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 52.0573 - val_loss: 108.0236\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 50.5924 - val_loss: 95.1489\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 49.0411 - val_loss: 103.6197\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 47.7485 - val_loss: 88.6497\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 46.3648 - val_loss: 90.8654\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 45.3640 - val_loss: 87.1592\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 43.8938 - val_loss: 82.9479\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 42.9143 - val_loss: 85.5177\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 41.9630 - val_loss: 78.6700\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 40.9992 - val_loss: 81.2547\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 40.1936 - val_loss: 89.8440\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 39.1492 - val_loss: 80.5717\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 37.9465 - val_loss: 79.9335\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 37.6564 - val_loss: 75.0180\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 36.7349 - val_loss: 75.2802\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 36.5100 - val_loss: 77.6031\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 35.4786 - val_loss: 68.0101\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 35.0123 - val_loss: 69.2041\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 33.6758 - val_loss: 67.4597\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 33.0614 - val_loss: 65.9055\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 32.9497 - val_loss: 75.0849\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 32.2531 - val_loss: 69.0435\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 31.7135 - val_loss: 62.8966\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 31.2005 - val_loss: 62.6828\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 30.7785 - val_loss: 60.3606\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 30.3382 - val_loss: 59.5249\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 30.4866 - val_loss: 60.7291\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 29.3365 - val_loss: 56.9531\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 29.1105 - val_loss: 56.7644\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 28.7611 - val_loss: 57.0657\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 28.2465 - val_loss: 53.3057\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 28.3106 - val_loss: 63.8865\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 27.6691 - val_loss: 52.3627\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 27.5181 - val_loss: 59.5456\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 26.8286 - val_loss: 51.4211\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 26.7434 - val_loss: 51.2392\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 26.5296 - val_loss: 62.9506\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 26.0240 - val_loss: 49.3693\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 26.6042 - val_loss: 49.3667\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 25.7781 - val_loss: 51.4636\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 25.7791 - val_loss: 48.0505\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 25.1878 - val_loss: 47.2106\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 24.6658 - val_loss: 47.2831\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 24.7727 - val_loss: 45.9710\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 24.5572 - val_loss: 44.4023\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 24.4897 - val_loss: 43.9420\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 24.1513 - val_loss: 43.2224\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 23.8372 - val_loss: 45.1933\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 23.6674 - val_loss: 44.0701\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 23.3226 - val_loss: 49.3090\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 23.1743 - val_loss: 41.7022\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 22.7455 - val_loss: 47.7214\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 23.0267 - val_loss: 40.6252\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 22.1319 - val_loss: 39.5098\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 22.3170 - val_loss: 41.0543\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 21.8399 - val_loss: 38.2466\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 22.2604 - val_loss: 38.0485\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 21.5306 - val_loss: 37.5387\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 21.5106 - val_loss: 37.5787\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 21.3428 - val_loss: 37.5674\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 20.9458 - val_loss: 36.9681\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 20.9319 - val_loss: 37.1730\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 21.3218 - val_loss: 35.6640\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 20.1210 - val_loss: 36.3858\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 20.5380 - val_loss: 35.1887\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 20.6446 - val_loss: 34.4321\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 20.1479 - val_loss: 38.6490\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 19.8990 - val_loss: 33.6905\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 19.7311 - val_loss: 33.6191\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 19.7396 - val_loss: 33.6172\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 19.5130 - val_loss: 33.3381\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 19.5506 - val_loss: 32.5739\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 19.3982 - val_loss: 34.6704\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 18.8377 - val_loss: 31.3436\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29.6403\n",
      "Loss: 29.64032\n",
      "68/68 [==============================] - 0s 1ms/step\n",
      "MSE: 29.64032\n",
      "MAE: 2.95438\n"
     ]
    }
   ],
   "source": [
    "# Neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_dim=x_train.shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# # Create an Adam optimizer with a specific learning rate\n",
    "decay_lr = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.001,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.88 ,\n",
    "    staircase=True\n",
    ")\n",
    "initial_learning_rate = 0.01\n",
    "decay_steps = 1000\n",
    "end_learning_rate = 1e-5\n",
    "power = 1.0\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps,\n",
    "    end_learning_rate,\n",
    "    power\n",
    ")\n",
    "# optm = tf.keras.optimizers.Adam(learning_rate=decay_lr)\n",
    "# optm = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule)\n",
    "# Compile the model using the specified optimizer\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "# Define an early stopping callback\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_loss',  # Monitor validation loss\n",
    "#     patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "#     restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored metric\n",
    "# )\n",
    "\n",
    "# train the model\n",
    "# model.fit(x_train, y_train, epochs=100, batch_size=500, validation_data=(x_test, y_test), callbacks=[early_stopping])\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "custom_early_stopping = CustomEarlyStopping()\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    # callbacks=[custom_early_stopping]\n",
    "    # verbose=0\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# Evaluate the model on the test set\n",
    "test_loss = model.evaluate(x_test, y_test)\n",
    "print(f\"Loss: {test_loss:.5f}\")#, Accuracy: {test_acc*100:.2f}%\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.5f}\")\n",
    "print(f\"MAE: {mae:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
